{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Embedding Distance Measures \n",
    "\n",
    "In this notebook, we demonstrate how to use different embedding distance measures to select the embedding dimension to minimize downstream instability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compare two pairs of embeddings, 25-dim and 100-dim embeddings trained on the Wiki'2017 and Wiki'2018 datasets. The goal is to choose the pair of embeddings with the smaller embedding distance, in order to select the dimension that is expected to have lower downstream instability. Given the results of our study in our MLSys 2020 paper \"Understanding the Downstream Instability of Word Embeddings\", where we found higher dimension generally improves stability, we want the embedding distance measure to select the 100-dim (higher dimensional) embeddings. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Distance Computation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we use five embedding distance measures (Eigenspace instability measure, k-NN measure, semantic displacement, PIP loss, and eigenspace overlap scprre) to compute the embedding distance between the two pairs of embeddings (i.e., `dist(emb_2017_dim_25, emb_2018_dim_25)` and `dist(emb_2017_dim_100, emb_2018_dim_100)`). \n",
    "\n",
    "Note: we subtract the k-NN and eigenspace overlap values from 1 since a larger value for these measures indicates greater stability (and we want a smaller value to uniformly indicate greater stability across the distance measures). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anchor.embedding import Embedding\n",
    "import numpy as np \n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load embeddings \n",
    "\n",
    "# same anchor embeddings for both dimension settings (use largest dimension)\n",
    "emb1_anchor = Embedding('../demo/glove_wiki_2017_dim_100.txt')\n",
    "emb2_anchor = Embedding('../demo/glove_wiki_2018_dim_100.txt')\n",
    "\n",
    "emb1_dim_25 = Embedding('../demo/glove_wiki_2017_dim_25.txt')\n",
    "emb2_dim_25 = Embedding('../demo/glove_wiki_2018_dim_25.txt')\n",
    "\n",
    "emb1_dim_100 = Embedding('../demo/glove_wiki_2017_dim_100.txt')\n",
    "emb2_dim_100 = Embedding('../demo/glove_wiki_2018_dim_100.txt')\n",
    "\n",
    "# use the top-10000 most frequent words \n",
    "n = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenspace Instability Measure (EIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "eis_dim_25 = emb2_dim_25.eis(emb1_dim_25, curr_anchor=emb2_anchor, other_anchor=emb1_anchor, n=n, exp=3)\n",
    "eis_dim_100 = emb2_dim_100.eis(emb1_dim_100, curr_anchor=emb2_anchor, other_anchor=emb1_anchor, n=n, exp=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN Measure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_dim_25 = 1-emb2_dim_25.knn(emb1_dim_25, n=n)\n",
    "knn_dim_100 = 1-emb2_dim_100.knn(emb1_dim_100, n=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Displacement (SD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_disp_dim_25 = emb2_dim_25.sem_disp(emb1_dim_25, n=n)\n",
    "sem_disp_dim_100 = emb2_dim_100.sem_disp(emb1_dim_100, n=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIP Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_dim_25 = emb2_dim_25.pip_loss(emb1_dim_25, n=n)\n",
    "pip_dim_100 = emb2_dim_100.pip_loss(emb1_dim_100, n=n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eigenspace Overlap Score (EO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eo_dim_25 = 1-emb2_dim_25.eigen_overlap(emb1_dim_25, n=10000)\n",
    "eo_dim_100 = 1-emb2_dim_100.eigen_overlap(emb1_dim_100, n=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the above results to make a prediction for the more stable dimension for each embedding distance measure.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>25-dim distance</th>\n",
       "      <th>100-dim distance</th>\n",
       "      <th>Vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EIS</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>100-dim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 - k-NN</th>\n",
       "      <td>0.231</td>\n",
       "      <td>0.156</td>\n",
       "      <td>100-dim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.036</td>\n",
       "      <td>25-dim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PIP</th>\n",
       "      <td>11697.035</td>\n",
       "      <td>11563.472</td>\n",
       "      <td>100-dim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 - EO</th>\n",
       "      <td>0.127</td>\n",
       "      <td>0.199</td>\n",
       "      <td>25-dim</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          25-dim distance  100-dim distance     Vote\n",
       "EIS                 0.001             0.001  100-dim\n",
       "1 - k-NN            0.231             0.156  100-dim\n",
       "SD                  0.021             0.036   25-dim\n",
       "PIP             11697.035         11563.472  100-dim\n",
       "1 - EO              0.127             0.199   25-dim"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_vote(dim_25, dim_100): \n",
    "    return [\"25-dim\", \"100-dim\"][np.argmin([dim_25, dim_100])]\n",
    "\n",
    "# Create a table with predictions \n",
    "cols = [\"25-dim distance\", \"100-dim distance\", \"Vote\"]\n",
    "rows = [\"EIS\", \"1 - k-NN\", \"SD\", \"PIP\", \"1 - EO\"]\n",
    "data = np.array([[eis_dim_25, eis_dim_100, get_vote(eis_dim_25, eis_dim_100)],\n",
    "                 [knn_dim_25, knn_dim_100, get_vote(knn_dim_25, knn_dim_100)],\n",
    "                 [sem_disp_dim_25, sem_disp_dim_100, get_vote(sem_disp_dim_25, sem_disp_dim_100)], \n",
    "                 [pip_dim_25, pip_dim_100, get_vote(pip_dim_25, pip_dim_100)], \n",
    "                 [eo_dim_25, eo_dim_100, get_vote(eo_dim_25, eo_dim_100)]])\n",
    "df = pandas.DataFrame(data, rows, cols)\n",
    "df[['25-dim distance', '100-dim distance']] = df[['25-dim distance', '100-dim distance']].astype(float)\n",
    "df.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see in the table above, on these pairs of embeddings, the EIS measure, k-NN measure, and PIP loss correctly choose the 100-dim embedding pair as more stable. Over different precision and dimension configurations, we find that our theoretically grounded EIS measure, and the k-NN measure, for which we have no theoretical guarantees, are the top-performing measures. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
